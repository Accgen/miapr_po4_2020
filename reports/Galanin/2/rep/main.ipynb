{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №2\n",
    "\n",
    "**Тема**: \"Линейная искусственная нейронная сеть. Адаптивный шаг обучения.\"\n",
    "\n",
    "**Цель работы**: Изучить обучение и функционирование линейной ИНС с применением адаптивного шага.\n",
    "\n",
    "**Условие:**\n",
    "\n",
    "1. Выбор адаптивного шага обучения\n",
    "\n",
    "Для ускорения процедуры обучения градиентного спуска, вместо постоянного шага обучения можно использовать адаптивный шаг обучения $\\alpha(t)$. Назовем <u>адаптивным шагом обучения</u> такой шаг, который целенаправленно выбирается на каждом этапе алгоритма таким образом, чтобы минимизировать среднеквадратичную ошибку сети.\n",
    "\n",
    "Рассмотрим линейную нейронную сеть, которая состоит из распределительного слоя нейронных элементов и выходного слоя\n",
    "\n",
    "**Ход работы:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a = 1.000000000000       - parametr for function y\n",
      "     b = 9.000000000000       - parametr for function y\n",
      "     d = 0.500000000000       - parametr for function y\n",
      "     L = 4                    - numbers of inputs NN\n",
      "    Em = 0.000000000010       - minimal squared error\n",
      "     T = 0.500000000000       - Threshold\n",
      "     m = 30                   - number of training iterations\n",
      "    m2 = 15                   - number of forecasting iterations\n",
      "\n",
      "= = = = = - - - - - Constantly alpha - - - - - = = = = =\n",
      "\n",
      "w[  0] =       0.007102732690 - weight\n",
      "w[  1] =      -0.004612100370 - weight\n",
      "w[  2] =       0.008310415520 - weight\n",
      "w[  3] =      -0.003240443731 - weight\n",
      "e[  0] =       0.500000000000 - etalon value\n",
      "e[  1] =       1.283326909627 - etalon value\n",
      "e[  2] =       1.473847630878 - etalon value\n",
      "e[  3] =       0.927379880234 - etalon value\n",
      "e[  4] =       0.057479556705 - etalon value\n",
      "e[  5] =      -0.477530117665 - etalon value\n",
      "e[  6] =      -0.272764487556 - etalon value\n",
      "e[  7] =       0.516813900484 - etalon value\n",
      "e[  8] =       1.293667863849 - etalon value\n",
      "e[  9] =       1.469889810845 - etalon value\n",
      "e[ 10] =       0.912118485242 - etalon value\n",
      "e[ 11] =       0.042464106225 - etalon value\n",
      "e[ 12] =      -0.480936230066 - etalon value\n",
      "e[ 13] =      -0.261983583919 - etalon value\n",
      "e[ 14] =       0.533623047221 - etalon value\n",
      "e[ 15] =       1.303784426552 - etalon value\n",
      "e[ 16] =       1.465657776549 - etalon value\n",
      "e[ 17] =       0.896740573131 - etalon value\n",
      "e[ 18] =       0.027578013602 - etalon value\n",
      "e[ 19] =      -0.484065005082 - etalon value\n",
      "e[ 20] =      -0.250987246772 - etalon value\n",
      "e[ 21] =       0.550422687807 - etalon value\n",
      "e[ 22] =       1.313673737507 - etalon value\n",
      "e[ 23] =       1.461152724502 - etalon value\n",
      "e[ 24] =       0.881250491655 - etalon value\n",
      "e[ 25] =       0.012825487539 - etalon value\n",
      "e[ 26] =      -0.486915558121 - etalon value\n",
      "e[ 27] =      -0.239778585078 - etalon value\n",
      "e[ 28] =       0.567208072525 - etalon value\n",
      "e[ 29] =       1.323333000738 - etalon value\n",
      "e[ 30] =       1.456375928405 - etalon value\n",
      "e[ 31] =       0.865652620283 - etalon value\n",
      "e[ 32] =      -0.001789301021 - etalon value\n",
      "e[ 33] =      -0.489487083255 - etalon value\n",
      "e[ 34] =      -0.228360767832 - etalon value\n",
      "e[ 35] =       0.583974455692 - etalon value\n",
      "e[ 36] =       1.332759485308 - etalon value\n",
      "e[ 37] =       1.451328738787 - etalon value\n",
      "e[ 38] =       0.849951368957 - etalon value\n",
      "e[ 39] =      -0.016262220080 - etalon value\n",
      "e[ 40] =      -0.491778853443 - etalon value\n",
      "e[ 41] =      -0.216737023161 - etalon value\n",
      "e[ 42] =       0.600717096993 - etalon value\n",
      "e[ 43] =       1.341950526092 - etalon value\n",
      "e[ 44] =       1.446012582627 - etalon value\n",
      "|                 Eras |                    E |\n",
      "| -------------------- | -------------------- |\n",
      "|                    1 |      36.804194411229 |\n",
      "|                    2 |       0.044432830536 |\n",
      "|                    3 |       0.000273611788 |\n",
      "|                    4 |       0.000000055968 |\n",
      "|                    5 |       0.000000000468 |\n",
      "|                    6 |       0.000000000000 |\n",
      "Result learning\n",
      "|                  y[] |   Эталонное значение |  Полученное значение |           Отклонение |\n",
      "| -------------------- | -------------------- | -------------------- | -------------------- |\n",
      "|                    0 |       0.057479556705 |       0.057479548362 |       0.000000008343 |\n",
      "|                    1 |      -0.477530117665 |      -0.477530122423 |       0.000000004758 |\n",
      "|                    2 |      -0.272764487556 |      -0.272764487903 |       0.000000000347 |\n",
      "|                    3 |       0.516813900484 |       0.516813902036 |      -0.000000001551 |\n",
      "|                    4 |       1.293667863849 |       1.293667863350 |       0.000000000499 |\n",
      "|                    5 |       1.469889810845 |       1.469889805898 |       0.000000004947 |\n",
      "|                    6 |       0.912118485242 |       0.912118476816 |       0.000000008426 |\n",
      "|                    7 |       0.042464106225 |       0.042464097921 |       0.000000008303 |\n",
      "|                    8 |      -0.480936230066 |      -0.480936234738 |       0.000000004672 |\n",
      "|                    9 |      -0.261983583919 |      -0.261983584199 |       0.000000000280 |\n",
      "|                   10 |       0.533623047221 |       0.533623048770 |      -0.000000001549 |\n",
      "|                   11 |       1.303784426552 |       1.303784425982 |       0.000000000570 |\n",
      "|                   12 |       1.465657776549 |       1.465657771517 |       0.000000005032 |\n",
      "|                   13 |       0.896740573131 |       0.896740564669 |       0.000000008461 |\n",
      "|                   14 |       0.027578013602 |       0.027578005339 |       0.000000008262 |\n",
      "|                   15 |      -0.484065005082 |      -0.484065009667 |       0.000000004585 |\n",
      "|                   16 |      -0.250987246772 |      -0.250987246985 |       0.000000000213 |\n",
      "|                   17 |       0.550422687807 |       0.550422689352 |      -0.000000001545 |\n",
      "|                   18 |       1.313673737507 |       1.313673736866 |       0.000000000641 |\n",
      "|                   19 |       1.461152724502 |       1.461152719386 |       0.000000005117 |\n",
      "|                   20 |       0.881250491655 |       0.881250483160 |       0.000000008495 |\n",
      "|                   21 |       0.012825487539 |       0.012825479319 |       0.000000008220 |\n",
      "|                   22 |      -0.486915558121 |      -0.486915562620 |       0.000000004499 |\n",
      "|                   23 |      -0.239778585078 |      -0.239778585226 |       0.000000000148 |\n",
      "|                   24 |       0.567208072525 |       0.567208074065 |      -0.000000001540 |\n",
      "|                   25 |       1.323333000738 |       1.323333000025 |       0.000000000713 |\n",
      "|                   26 |       1.456375928405 |       1.456375923204 |       0.000000005201 |\n",
      "|                   27 |       0.865652620283 |       0.865652611755 |       0.000000008528 |\n",
      "|                   28 |      -0.001789301021 |      -0.001789309197 |       0.000000008176 |\n",
      "|                   29 |      -0.489487083255 |      -0.489487087667 |       0.000000004412 |\n",
      "Results forecasting\n",
      "|                  y[] |   Эталонное значение |  Полученное значение |           Отклонение |\n",
      "| -------------------- | -------------------- | -------------------- | -------------------- |\n",
      "|                   30 |       1.456375928405 |       1.456375923204 |       0.000000005201 |\n",
      "|                   31 |       0.865652620283 |       0.865652611755 |       0.000000008528 |\n",
      "|                   32 |      -0.001789301021 |      -0.001789309197 |       0.000000008176 |\n",
      "|                   33 |      -0.489487083255 |      -0.489487087667 |       0.000000004412 |\n",
      "|                   34 |      -0.228360767832 |      -0.228360767915 |       0.000000000084 |\n",
      "|                   35 |       0.583974455692 |       0.583974457225 |      -0.000000001533 |\n",
      "|                   36 |       1.332759485308 |       1.332759484522 |       0.000000000785 |\n",
      "|                   37 |       1.451328738787 |       1.451328733502 |       0.000000005284 |\n",
      "|                   38 |       0.849951368957 |       0.849951360397 |       0.000000008559 |\n",
      "|                   39 |      -0.016262220080 |      -0.016262228212 |       0.000000008132 |\n",
      "|                   40 |      -0.491778853443 |      -0.491778857768 |       0.000000004325 |\n",
      "|                   41 |      -0.216737023161 |      -0.216737023181 |       0.000000000021 |\n",
      "|                   42 |       0.600717096993 |       0.600717098517 |      -0.000000001525 |\n",
      "|                   43 |       1.341950526092 |       1.341950525233 |       0.000000000859 |\n",
      "|                   44 |       1.446012582627 |       1.446012577259 |       0.000000005368 |\n",
      "\n",
      "= = = = = - - - - - Adaptive alpha - - - - - = = = = =\n",
      "\n",
      "w[  0] =      -0.001782169538 - weight\n",
      "w[  1] =      -0.000335722561 - weight\n",
      "w[  2] =       0.009929038858 - weight\n",
      "w[  3] =      -0.002641021376 - weight\n",
      "e[  0] =       0.500000000000 - etalon value\n",
      "e[  1] =       1.283326909627 - etalon value\n",
      "e[  2] =       1.473847630878 - etalon value\n",
      "e[  3] =       0.927379880234 - etalon value\n",
      "e[  4] =       0.057479556705 - etalon value\n",
      "e[  5] =      -0.477530117665 - etalon value\n",
      "e[  6] =      -0.272764487556 - etalon value\n",
      "e[  7] =       0.516813900484 - etalon value\n",
      "e[  8] =       1.293667863849 - etalon value\n",
      "e[  9] =       1.469889810845 - etalon value\n",
      "e[ 10] =       0.912118485242 - etalon value\n",
      "e[ 11] =       0.042464106225 - etalon value\n",
      "e[ 12] =      -0.480936230066 - etalon value\n",
      "e[ 13] =      -0.261983583919 - etalon value\n",
      "e[ 14] =       0.533623047221 - etalon value\n",
      "e[ 15] =       1.303784426552 - etalon value\n",
      "e[ 16] =       1.465657776549 - etalon value\n",
      "e[ 17] =       0.896740573131 - etalon value\n",
      "e[ 18] =       0.027578013602 - etalon value\n",
      "e[ 19] =      -0.484065005082 - etalon value\n",
      "e[ 20] =      -0.250987246772 - etalon value\n",
      "e[ 21] =       0.550422687807 - etalon value\n",
      "e[ 22] =       1.313673737507 - etalon value\n",
      "e[ 23] =       1.461152724502 - etalon value\n",
      "e[ 24] =       0.881250491655 - etalon value\n",
      "e[ 25] =       0.012825487539 - etalon value\n",
      "e[ 26] =      -0.486915558121 - etalon value\n",
      "e[ 27] =      -0.239778585078 - etalon value\n",
      "e[ 28] =       0.567208072525 - etalon value\n",
      "e[ 29] =       1.323333000738 - etalon value\n",
      "e[ 30] =       1.456375928405 - etalon value\n",
      "e[ 31] =       0.865652620283 - etalon value\n",
      "e[ 32] =      -0.001789301021 - etalon value\n",
      "e[ 33] =      -0.489487083255 - etalon value\n",
      "e[ 34] =      -0.228360767832 - etalon value\n",
      "e[ 35] =       0.583974455692 - etalon value\n",
      "e[ 36] =       1.332759485308 - etalon value\n",
      "e[ 37] =       1.451328738787 - etalon value\n",
      "e[ 38] =       0.849951368957 - etalon value\n",
      "e[ 39] =      -0.016262220080 - etalon value\n",
      "e[ 40] =      -0.491778853443 - etalon value\n",
      "e[ 41] =      -0.216737023161 - etalon value\n",
      "e[ 42] =       0.600717096993 - etalon value\n",
      "e[ 43] =       1.341950526092 - etalon value\n",
      "e[ 44] =       1.446012582627 - etalon value\n",
      "|                 Eras |                    E |\n",
      "| -------------------- | -------------------- |\n",
      "|                    1 |       0.857097665671 |\n",
      "|                    2 |       0.001918354598 |\n",
      "|                    3 |       0.000001467111 |\n",
      "|                    4 |       0.000000003041 |\n",
      "|                    5 |       0.000000000005 |\n",
      "Result learning\n",
      "|                  y[] |   Эталонное значение |  Полученное значение |           Отклонение |\n",
      "| -------------------- | -------------------- | -------------------- | -------------------- |\n",
      "|                    0 |       0.057479556705 |       0.057479475758 |       0.000000080947 |\n",
      "|                    1 |      -0.477530117665 |      -0.477530138085 |       0.000000020419 |\n",
      "|                    2 |      -0.272764487556 |      -0.272764450692 |      -0.000000036864 |\n",
      "|                    3 |       0.516813900484 |       0.516813948036 |      -0.000000047552 |\n",
      "|                    4 |       1.293667863849 |       1.293667867405 |      -0.000000003556 |\n",
      "|                    5 |       1.469889810845 |       1.469889749017 |       0.000000061828 |\n",
      "|                    6 |       0.912118485242 |       0.912118386123 |       0.000000099119 |\n",
      "|                    7 |       0.042464106225 |       0.042464026128 |       0.000000080096 |\n",
      "|                    8 |      -0.480936230066 |      -0.480936249222 |       0.000000019156 |\n",
      "|                    9 |      -0.261983583919 |      -0.261983546335 |      -0.000000037584 |\n",
      "|                   10 |       0.533623047221 |       0.533623094405 |      -0.000000047184 |\n",
      "|                   11 |       1.303784426552 |       1.303784428930 |      -0.000000002378 |\n",
      "|                   12 |       1.465657776549 |       1.465657713625 |       0.000000062924 |\n",
      "|                   13 |       0.896740573131 |       0.896740473826 |       0.000000099305 |\n",
      "|                   14 |       0.027578013602 |       0.027577934371 |       0.000000079230 |\n",
      "|                   15 |      -0.484065005082 |      -0.484065022975 |       0.000000017893 |\n",
      "|                   16 |      -0.250987246772 |      -0.250987208484 |      -0.000000038288 |\n",
      "|                   17 |       0.550422687807 |       0.550422734603 |      -0.000000046796 |\n",
      "|                   18 |       1.313673737507 |       1.313673738700 |      -0.000000001193 |\n",
      "|                   19 |       1.461152724502 |       1.461152660492 |       0.000000064010 |\n",
      "|                   20 |       0.881250491655 |       0.881250392186 |       0.000000099469 |\n",
      "|                   21 |       0.012825487539 |       0.012825409191 |       0.000000078349 |\n",
      "|                   22 |      -0.486915558121 |      -0.486915574754 |       0.000000016633 |\n",
      "|                   23 |      -0.239778585078 |      -0.239778546105 |      -0.000000038973 |\n",
      "|                   24 |       0.567208072525 |       0.567208118913 |      -0.000000046388 |\n",
      "|                   25 |       1.323333000738 |       1.323333000738 |       0.000000000000 |\n",
      "|                   26 |       1.456375928405 |       1.456375863319 |       0.000000065085 |\n",
      "|                   27 |       0.865652620283 |       0.865652520670 |       0.000000099612 |\n",
      "|                   28 |      -0.001789301021 |      -0.001789378473 |       0.000000077452 |\n",
      "|                   29 |      -0.489487083255 |      -0.489487098630 |       0.000000015375 |\n",
      "Results forecasting\n",
      "|                  y[] |   Эталонное значение |  Полученное значение |           Отклонение |\n",
      "| -------------------- | -------------------- | -------------------- | -------------------- |\n",
      "|                   30 |       1.456375928405 |       1.456375863319 |       0.000000065085 |\n",
      "|                   31 |       0.865652620283 |       0.865652520670 |       0.000000099612 |\n",
      "|                   32 |      -0.001789301021 |      -0.001789378473 |       0.000000077452 |\n",
      "|                   33 |      -0.489487083255 |      -0.489487098630 |       0.000000015375 |\n",
      "|                   34 |      -0.228360767832 |      -0.228360728191 |      -0.000000039640 |\n",
      "|                   35 |       0.583974455692 |       0.583974501651 |      -0.000000045959 |\n",
      "|                   36 |       1.332759485308 |       1.332759484108 |       0.000000001200 |\n",
      "|                   37 |       1.451328738787 |       1.451328672638 |       0.000000066148 |\n",
      "|                   38 |       0.849951368957 |       0.849951269222 |       0.000000099734 |\n",
      "|                   39 |      -0.016262220080 |      -0.016262296621 |       0.000000076541 |\n",
      "|                   40 |      -0.491778853443 |      -0.491778867563 |       0.000000014120 |\n",
      "|                   41 |      -0.216737023161 |      -0.216736982871 |      -0.000000040289 |\n",
      "|                   42 |       0.600717096993 |       0.600717142504 |      -0.000000045511 |\n",
      "|                   43 |       1.341950526092 |       1.341950523686 |       0.000000002406 |\n",
      "|                   44 |       1.446012582627 |       1.446012515427 |       0.000000067200 |\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class lab():\n",
    "\tdef __init__(self, a, b, d, L, Em, T, m, m2):\n",
    "\t\tself.a = a\n",
    "\t\tprint(\"%6s = %-20.12f - parametr for function y\" % (\"a\", self.a))\n",
    "\n",
    "\t\tself.b = b\n",
    "\t\tprint(\"%6s = %-20.12f - parametr for function y\" % (\"b\", self.b))\n",
    "\n",
    "\t\tself.d = d\n",
    "\t\tprint(\"%6s = %-20.12f - parametr for function y\" % (\"d\", self.d))\n",
    "\n",
    "\t\tself.L = L\n",
    "\t\tprint(\"%6s = %-20d - numbers of inputs NN\" % (\"L\", self.L))\n",
    "\n",
    "\t\tself.Em = Em\n",
    "\t\tprint(\"%6s = %-20.12f - minimal squared error\" % (\"Em\", self.Em))\n",
    "\n",
    "\t\tself.T = T\n",
    "\t\tprint(\"%6s = %-20.12f - Threshold\" % (\"T\", self.T))\n",
    "\n",
    "\t\tself.m = m\n",
    "\t\tprint(\"%6s = %-20d - number of training iterations\" % (\"m\", self.m))\n",
    "\n",
    "\t\tself.m2 = m2\n",
    "\t\tprint(\"%6s = %-20d - number of forecasting iterations\" % (\"m2\", self.m2))\n",
    "\n",
    "\tdef generate_w(self, left_point, right_point):\n",
    "\t\tself.w = []\n",
    "\t\tfor i in range(self.L):\n",
    "\t\t\tself.w.append(random.random() * right_point - left_point)\n",
    "\n",
    "\tdef print_w(self):\n",
    "\t\tfor i in range(self.L):\n",
    "\t\t\tprint(\"w[%3d] = %20.12f - weight\" % (i, self.w[i]))\n",
    "\n",
    "\tdef generate_e(self, step):\n",
    "\t\tself.e = []\n",
    "\t\tfor i in range(self.m + self.m2):\n",
    "\t\t\tx = step * i\n",
    "\t\t\tresult = self.a * math.sin( self.b * x ) + self.d\n",
    "\t\t\tself.e.append(result)\n",
    "\n",
    "\tdef print_e(self):\n",
    "\t\tfor i in range(self.m + self.m2):\n",
    "\t\t\tprint(\"e[%3d] = %20.12f - etalon value\" % (i, self.e[i]))\n",
    "\n",
    "\tdef WidrowHoffAlgorithm_constAlpha(self, alpha):\n",
    "\t\tprint(\"| %20s | %20s |\" % (\"Eras\", \"E\"))\n",
    "\t\tprint(\"| %16s | %16s |\" % (\"--------------------\", \"--------------------\"))\n",
    "\n",
    "\t\teras = 0\n",
    "\t\tvalueXforGraph = []\n",
    "\t\tvalueYforGraph = []\n",
    "\t\twhile 1:\n",
    "\t\t\tE = 0\n",
    "\t\t\tfor i in range(self.m - self.L):\n",
    "\t\t\t\ty1 = 0\n",
    "\t\t\t\tfor j in range(self.L):\n",
    "\t\t\t\t\ty1 += self.w[j] * self.e[i + j]\n",
    "\t\t\t\ty1 -= self.T\n",
    "\t\t\t\tfor j in range(self.L):\n",
    "\t\t\t\t\tself.w[j] -= alpha * (y1 - self.e[i + self.L]) * self.e[i + j]\n",
    "\t\t\t\tself.T += alpha * (y1 - self.e[i + self.L])\n",
    "\t\t\t\tE += 0.5 * math.pow( (y1 - self.e[i + self.L]), 2 )\n",
    "\n",
    "\t\t\teras += 1\n",
    "\t\t\tprint(\"| %20d | %20.12f |\" % (eras, E))\n",
    "\t\t\tvalueXforGraph.append(eras)\n",
    "\t\t\tvalueYforGraph.append(E)\n",
    "\n",
    "\t\t\tif E < self.Em:\n",
    "\t\t\t\tbreak\n",
    "\t\tplt.plot(valueXforGraph, valueYforGraph, 'Db', label=\"Contantly alpha\")\n",
    "\n",
    "\tdef WidrowHoffAlgorithm_adaptiveAlpha(self, alpha):\n",
    "\t\tprint(\"| %20s | %20s |\" % (\"Eras\", \"E\"))\n",
    "\t\tprint(\"| %16s | %16s |\" % (\"--------------------\", \"--------------------\"))\n",
    "\n",
    "\t\teras = 0\n",
    "\t\tvalueXforGraph = []\n",
    "\t\tvalueYforGraph = []\n",
    "\t\twhile 1:\n",
    "\t\t\tE = 0\n",
    "\t\t\tfor i in range(self.m - self.L):\n",
    "\n",
    "\t\t\t\tx2 = 0\n",
    "\t\t\t\tfor q in range(self.L):\n",
    "\t\t\t\t\tx2 += pow(self.e[i + q], 2)\n",
    "\t\t\t\talpha = 1 / (1 + x2)\n",
    "\n",
    "\t\t\t\ty1 = 0\n",
    "\t\t\t\tfor j in range(self.L):\n",
    "\t\t\t\t\ty1 += self.w[j] * self.e[i + j]\n",
    "\t\t\t\ty1 -= self.T\n",
    "\t\t\t\tfor j in range(self.L):\n",
    "\t\t\t\t\tself.w[j] -= alpha * (y1 - self.e[i + self.L]) * self.e[i + j]\n",
    "\t\t\t\tself.T += alpha * (y1 - self.e[i + self.L])\n",
    "\t\t\t\tE += 0.5 * math.pow( (y1 - self.e[i + self.L]), 2 )\n",
    "\n",
    "\t\t\teras += 1\n",
    "\t\t\tprint(\"| %20d | %20.12f |\" % (eras, E))\n",
    "\t\t\tvalueXforGraph.append(eras)\n",
    "\t\t\tvalueYforGraph.append(E)\n",
    "\n",
    "\t\t\tif E < self.Em:\n",
    "\t\t\t\tbreak\n",
    "\t\tplt.plot(valueXforGraph, valueYforGraph, 'py', label=\"Adaptive alpha\")\n",
    "\n",
    "\tdef printResult(self):\n",
    "\t\tdef print_headTable():\n",
    "\t\t\tprint(\"| %20s | %20s | %20s | %20s |\" % (\n",
    "\t\t\t\t\"y[]\",\n",
    "\t\t\t\t\"Эталонное значение\",\n",
    "\t\t\t\t\"Полученное значение\",\n",
    "\t\t\t\t\"Отклонение\"\n",
    "\t\t\t))\n",
    "\t\t\tprint(\"| %16s | %16s | %16s | %16s |\" % (\n",
    "\t\t\t\t\"--------------------\",\n",
    "\t\t\t\t\"--------------------\",\n",
    "\t\t\t\t\"--------------------\",\n",
    "\t\t\t\t\"--------------------\"\n",
    "\t\t\t))\n",
    "\n",
    "\t\ttrainingSample = []\n",
    "\t\tprint(\"Result learning\")\n",
    "\t\tprint_headTable()\n",
    "\t\tfor i in range(self.m):\n",
    "\t\t\ttrainingSample.append(0)\n",
    "\t\t\tfor j in range(self.L):\n",
    "\t\t\t\ttrainingSample[i] += self.w[j] * self.e[j + i]\n",
    "\t\t\ttrainingSample[i] -= self.T\n",
    "\t\t\tprint(\"| %20d | %20.12f | %20.12f | %20.12f |\" % (\n",
    "\t\t\t\ti,\n",
    "\t\t\t\tself.e[i + self.L],\n",
    "\t\t\t\ttrainingSample[i],\n",
    "\t\t\t\tself.e[i + self.L] - trainingSample[i]\n",
    "\t\t\t))\n",
    "\n",
    "\t\tprint(\"Results forecasting\")\n",
    "\t\tprint_headTable()\n",
    "\t\tfor i in range(self.m2):\n",
    "\t\t\ttrainingSample.append(0)\n",
    "\t\t\tfor j in range(self.L):\n",
    "\t\t\t\ttrainingSample[i + self.m] += self.w[j] * self.e[self.m - self.L + j + i]\n",
    "\t\t\ttrainingSample[i + self.m] -= self.T\n",
    "\t\t\tprint(\"| %20d | %20.12f | %20.12f | %20.12f |\" % (\n",
    "\t\t\t\ti + self.m,\n",
    "\t\t\t\tself.e[i + self.m],\n",
    "\t\t\t\ttrainingSample[i + self.m],\n",
    "\t\t\t\tself.e[i + self.m] - trainingSample[i + self.m]\n",
    "\t\t\t))\n",
    "\n",
    "\"\"\"Main\"\"\"\n",
    "\n",
    "x = lab(\n",
    "\t1,\t\t# a argument for function y\n",
    "\t9,\t\t# b argument for function y\n",
    "\t0.5,\t# d argument for function y\n",
    "\t4,\t\t# L number of inputs NN\n",
    "\t1e-11,\t# Em argument for algorithm\n",
    "\t0.5,\t# T argument for algorithm\n",
    "\t30,\t\t# m number of operations for training results\n",
    "\t15,\t\t# m2 numper of operation for forecasting results\n",
    ")\n",
    "\n",
    "print(\"\\n= = = = = - - - - - Constantly alpha - - - - - = = = = =\\n\")\n",
    "\n",
    "x.generate_w(0.01, 0.02) # arguments (left_point, right_point)\n",
    "x.print_w()\n",
    "\n",
    "x.generate_e(0.1) # argument (step) for y\n",
    "x.print_e()\n",
    "\n",
    "x.WidrowHoffAlgorithm_constAlpha(0.5) # argument (alpha)\n",
    "x.printResult()\n",
    "\n",
    "print(\"\\n= = = = = - - - - - Adaptive alpha - - - - - = = = = =\\n\")\n",
    "\n",
    "x.generate_w(0.01, 0.02) # arguments (left_point, right_point)\n",
    "x.print_w()\n",
    "\n",
    "x.generate_e(0.1) # argument (step) for y\n",
    "x.print_e()\n",
    "\n",
    "x.WidrowHoffAlgorithm_adaptiveAlpha(0.5) # argument (alpha)\n",
    "x.printResult()\n",
    "\n",
    "plt.title(\"Error change graph\") # Python write title in graph\n",
    "plt.legend() # Python write legend in graph\n",
    "plt.show() # Python open new windows and show graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**: \"Изучили обучение и функционирование линейной ИНС с применением адаптивного шага.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
