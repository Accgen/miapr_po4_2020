{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Минимстерство образования Республики Беларусь</center>\n",
    "\n",
    "<center>Учреждение образования</center>\n",
    "\n",
    "<center><<Брестский государственный технический университет>></center>\n",
    "\n",
    "<center>Кафедра ИИТ</center>\n",
    "\n",
    "<br /><br /><br /><br /><br /><br />\n",
    "\n",
    "<center>Лабораторная работа №4</center>\n",
    "\n",
    "<center>за 3 семестр</center>\n",
    "\n",
    "<center>по дисциплине: \"Методы и алгоритмы принятия решений\"</center>\n",
    "\n",
    "<center>Тема: \"Нелинейные ИНС в задачах прогнозирования\"</center>\n",
    "\n",
    "<br /><br /><br /><br /><br /><br />\n",
    "\n",
    "<div style=\"display: table; width: 100%;\">\n",
    "    <div style=\"float: right; width: 33%;\">\n",
    "        <p>Выполнил:</p>\n",
    "        <p>студент 2 курса</p>\n",
    "        <p>факультета ЭИС</p>\n",
    "        <p>группы ПО-4(1)</p>\n",
    "        <p>Галанин П. И.</p>\n",
    "        <br />\n",
    "        <p>Проверил:</p>\n",
    "        <p>ст. преподаватель</p>\n",
    "        <p>Крощенко А. А.</p>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<br /><br /><br /><br /><br /><br />\n",
    "\n",
    "<center>Брест 2020</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №4\n",
    "\n",
    "**Тема**: \"Нелинейные ИНС в задачах прогнозирования\".\n",
    "\n",
    "**Цель работы**: \"Изучить обучение и функционирование нелинейной ИНС при решении задач распознавания образов\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание (Лаб 3)**:\n",
    "\n",
    "1. Написать на любом ЯВУ программу моделирования прогнозирующей нелинейной ИНС. Для тестирования использовать функцию\n",
    "\n",
    "Варианты заданий приведены в следующей таблице:\n",
    "\n",
    "|№ варианта|a  |b  |с   |d  |Кол-во входов ИНС|Кол-во НЭ в скрытом слое|\n",
    "|:--------:|:-:|:-:|:--:|:-:|:---------------:|:----------------------:|\n",
    "|1         |0.1|0.1|0.05|0.1|6                |2                       |\n",
    "|2         |0.2|0.2|0.06|0.2|8                |3                       |\n",
    "|3         |0.3|0.3|0.07|0.3|10               |4                       |\n",
    "|4         |0.4|0.4|0.08|0.4|6                |2                       |\n",
    "|5         |0.1|0.5|0.09|0.5|8                |3                       |\n",
    "|6         |0.2|0.6|0.05|0.6|10               |4                       |\n",
    "|7         |0.3|0.1|0.06|0.1|6                |2                       |\n",
    "|8         |0.4|0.2|0.07|0.2|8                |3                       |\n",
    "|9         |0.1|0.3|0.08|0.3|10               |4                       |\n",
    "|10        |0.2|0.4|0.09|0.4|6                |2                       |\n",
    "|11        |0.3|0.5|0.05|0.5|8                |3                       |\n",
    "\n",
    "Для прогнозирования использовать многослойную ИНС с одним скрытым слоем. В качестве функций активации для скрытого слоя использовать сигмоидную функцию, для выходного - линейную.\n",
    "\n",
    "2. Результаты представить в виде отчета содержащего:\n",
    "    1. Титульный лист\n",
    "    2. Цель работы\n",
    "    3. Задание\n",
    "    4. График прогнозируемой функции на участке обучения\n",
    "    5. Результаты обучения:\n",
    "        - таблицу со столбцами:\n",
    "            - эталонное значение\n",
    "            - полученное значение\n",
    "            - отклонение\n",
    "        - график изменения ошибки в зависимости от итерации\n",
    "    6. Результаты прогнозирования:\n",
    "        - таблицу со столбцами:\n",
    "            - эталонное значение\n",
    "            - полученное значение\n",
    "            - отклонение\n",
    "    7. Выводы по лабораторной работе.\n",
    "    \n",
    "Результаты для пунктов 3 и 4 приводятся для значения $\\alpha$, при котором достигается минимальная ошибка. В выводах анализируются все полученные результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание (Лаб 4)**:\n",
    "\n",
    "1. Спрогнозировать нелинейный временной ряд,  применяя параметры лабораторной работы №3. При этом необходимо использовать алгоритм обучения многослойной ИНС с адаптивным шагом.\n",
    "2. Результаты представить в виде отчета содержащего:\n",
    "    1. Титульный лист,\n",
    "    2. Цель работы,\n",
    "    3. Задание,\n",
    "    4. График прогнозируемой функции на участке обучения,\n",
    "    5. Результаты обучения: таблицу  со столбцами: эталонное значение, полученное значение, отклонение; график изменения ошибки в зависимости от итерации.\n",
    "    6. Результаты прогнозирования: таблицу  со столбцами: эталонное значение, полученное значение, отклонение.\n",
    "    7. Выводы по лабораторной работе.\n",
    "    \n",
    "    В выводах сравнить полученные результаты с результатами лабораторной работы №3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ход работы**:\n",
    "\n",
    "Разработанная схема:\n",
    "\n",
    "![](../../3/rep/Scheme.png)\n",
    "\n",
    "Использованные формулы:\n",
    "\n",
    "Взвешенная сумма для скрытого слоя:\n",
    "\n",
    "$S_i = e * w_{ki} - T_i$\n",
    "\n",
    "Функция активации для скрытого слоя:\n",
    "\n",
    "$y_i = sigm(S_i)$\n",
    "\n",
    "Взвешенная сумма для выходного слоя:\n",
    "\n",
    "$s_j = y_i * w_{ki} - T_j$\n",
    "\n",
    "Функция активации для выходного слоя:\n",
    "\n",
    "$y_j = linear(S_j)$\n",
    "\n",
    "Ошибка нейронного элемента j-ого слоя:\n",
    "\n",
    "$\\gamma_j = y_j - e$\n",
    "\n",
    "Ошибка нейронного элемента i-ого слоя:\n",
    "\n",
    "$\\gamma_i = \\sum \\gamma_j * F'(S_j) * w_{ij}$\n",
    "\n",
    "Веса от скрытого слоя к выходному слою:\n",
    "\n",
    "$\\omega_{ij} = \\omega_{ij} - \\alpha * \\gamma_j * F'(S_j) * y_i$\n",
    "\n",
    "Пороги выходного слоя:\n",
    "\n",
    "$T_j = T_j + \\alpha * F'(S_j)$\n",
    "\n",
    "Веса от входного слоя к скрытому слою:\n",
    "\n",
    "$\\omega_{ki} = \\omega{ki} - \\alpha * \\gamma_i * F'(S_i) * y_i$\n",
    "\n",
    "Пороги скрытого слоя:\n",
    "\n",
    "$T_i = T_i + \\alpha * \\gamma_i * F(S_i)$\n",
    "\n",
    "Средняя квадратичная ошибка сети:\n",
    "\n",
    "$E = {1 \\over 2} \\sum(y_j - e)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from math import sin\n",
    "from math import cos\n",
    "import random\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция принимает параметры:\n",
    "# m1 - number neurons for learning\n",
    "# m2 - number neurons for test\n",
    "# a - parametr for etalon function\n",
    "# b - parametr for etalon function\n",
    "# c - parametr for etalon function\n",
    "# d - parametr for etalon function\n",
    "# step - parametr for etalon function\n",
    "# inputs - number neurons\n",
    "# hiddens - number neurons\n",
    "# outputs - number neurons\n",
    "# Ee - desired squared error\n",
    "# alpha_ki - learning rate (inputs - hiddens)\n",
    "# alpha_ij - learning rate (hiddens - outputs)\n",
    "def lab4(m1, m2, a, b, c, d, step, inputs, hiddens, outputs, Ee, alpha_ki, alpha_ij):\n",
    "    # Функция возвращает массив с эталонными значениями\n",
    "    def get_etalons(n):\n",
    "        etalons = numpy.zeros(n)\n",
    "        for i in range(len(etalons)):\n",
    "            x = step * i\n",
    "            y = a * cos(b * x) + c * sin(d * x)\n",
    "            etalons[i] = y\n",
    "        return etalons\n",
    "\n",
    "    etalons = get_etalons(m1 + m2)\n",
    "    #print(etalons)\n",
    "\n",
    "    # Функция возвращает массив с весами\n",
    "    # Например, 8 нейронов в входном слое и 3 в скрытом, тогда возвратит массив 8х3\n",
    "    # Например, 3 нейрона в скрытом слое и 1 нейрон в выходном слое, тогда возвратит массив 3х1\n",
    "    def get_weights(leftNumberNeurons, rightNumberNeurons, leftRandomBorder, rightRandomBorder):\n",
    "        weights = numpy.zeros((leftNumberNeurons, rightNumberNeurons))\n",
    "        for i in range(leftNumberNeurons):\n",
    "            for j in range(rightNumberNeurons):\n",
    "                weights[i][j] = random.uniform(leftRandomBorder, rightRandomBorder)\n",
    "        return weights\n",
    "\n",
    "    weights_ki = get_weights(inputs, hiddens, -1, 1)\n",
    "    #print(weights_ki)\n",
    "\n",
    "    weights_ij = get_weights(hiddens, outputs, -1, 1)\n",
    "    #print(weights_ij)\n",
    "\n",
    "    # Функция возвращает массив с порогами\n",
    "    # Например, 8 нейронов в входном слое и 3 в скрытом, тогда возвратит массив размером 3\n",
    "    # Например, 3 нейрона в скрытом слое и 1 нейрон в выходном слое, тогда возвратит массив размером 1\n",
    "    def get_thresholds(numberNeurons, leftRandomBorder, rightRandomBorder):\n",
    "        tresholds = numpy.zeros(numberNeurons)\n",
    "        for i in range(numberNeurons):\n",
    "            tresholds[i] = random.uniform(leftRandomBorder, rightRandomBorder)\n",
    "        return tresholds\n",
    "\n",
    "    tresholds_i = get_thresholds(hiddens, -1, 1)\n",
    "    #print(tresholds_i)\n",
    "\n",
    "    tresholds_j = get_thresholds(outputs, -1, 1)\n",
    "    #print(tresholds_j)\n",
    "\n",
    "    valuesXforGraph = []\n",
    "    valuesYforGraph = []\n",
    "    eras = 0\n",
    "    while 1:\n",
    "        for q in range(m1 - inputs):\n",
    "            # Si = x * wki - Ti\n",
    "            x = etalons[q:(q+inputs)]\n",
    "            S_i = x.dot(weights_ki) - tresholds_i\n",
    "            #print(S_i)\n",
    "            # yi = Sigm(Si)\n",
    "            y_i = numpy.zeros(len(S_i))\n",
    "            for i in range(len(S_i)):\n",
    "                y_i[i] = 1. / (1. + numpy.exp( - S_i[i] )) # sigmoid func\n",
    "            #print(y_i)\n",
    "            # Sj = yi * wij - Tj\n",
    "            S_j = y_i.dot(weights_ij) - tresholds_j\n",
    "            #print(S_j)\n",
    "            # yj = Linear(Sj) = Sj\n",
    "            y_j = S_j\n",
    "            #print(y_j)\n",
    "            # jj = yj - e\n",
    "            j_j = numpy.array([ y_j[i] - etalons[q + inputs + i] for i in range(len(y_j)) ])\n",
    "            #print(j_j)\n",
    "            # ji = sum [dF(Sj) * wij]\n",
    "            dF_j = 1\n",
    "            j_i = numpy.zeros(hiddens)\n",
    "            for i in range(hiddens):\n",
    "                for j in range(outputs):\n",
    "                    j_i[i] += j_j[j] * dF_j * weights_ij[i][j]\n",
    "            #print(j_i)\n",
    "\n",
    "            #for j in range(outputs):\n",
    "            sum1 = j_j**2 * (1 - y_j**2)\n",
    "\n",
    "            for i in range(hiddens):\n",
    "                sum2 = y_i[i]**2\n",
    "\n",
    "            #for j in range(hiddens):\n",
    "            sum3 = j_j**2 * y_j**2 * (1 - y_j)**2\n",
    "\n",
    "            alpha_ki = 4 * sum1 / ( (1 + sum2) * sum3 )\n",
    "\n",
    "            # wij = wij - alpha * jj * dFj * yi\n",
    "            for i in range(hiddens):\n",
    "                for j in range(outputs):\n",
    "                    weights_ij[i][j] -= alpha_ij * j_j[j] * dF_j * y_j[j]\n",
    "            #print(weights_ij)\n",
    "            # Tj = Tj + alpha * jj * dFj\n",
    "            for j in range(outputs):\n",
    "                tresholds_j += alpha_ij * j_j[j] * dF_j\n",
    "            #print(tresholds_j)\n",
    "            # wki = wki - alpha * ji * dFi * yi\n",
    "            for k in range(inputs):\n",
    "                for i in range(hiddens):\n",
    "                    dFi = y_i[i] * (1 - y_i[i]) # derivative sigmoid func\n",
    "                    weights_ki[k][i] -= alpha_ki * j_i[i] * dFi * y_i[i]\n",
    "            #print(weights_ki)\n",
    "            # Ti = Ti + alpha * ji * dFi\n",
    "            for i in range(hiddens):\n",
    "                dFi = y_i[i] * (1 - y_i[i]) # derivative sigmoid func\n",
    "                tresholds_i += alpha_ki * j_i[i] * dFi\n",
    "            #print(tresholds_i)\n",
    "        \n",
    "        E = 0\n",
    "        for j in range(outputs):\n",
    "            E += 1./2 * (y_j[j] - etalons[q + inputs + j]) ** 2\n",
    "        valuesXforGraph.append(E)\n",
    "        eras += 1\n",
    "        valuesYforGraph.append(eras)\n",
    "        print('eras: %8d\\tE: %32.20f\\r' % (eras, E), end = '')\n",
    "        if E < Ee:\n",
    "            print()\n",
    "            matplotlib.pyplot.plot(valuesYforGraph, valuesXforGraph, 'g-o')\n",
    "            matplotlib.pyplot.title('E(eras)')\n",
    "            break\n",
    "\n",
    "    print('after learning:')\n",
    "    for q in range(m1):\n",
    "        # Si = x * wki - Ti\n",
    "        x = etalons[q:(q+inputs)]\n",
    "        S_i = x.dot(weights_ki) - tresholds_i\n",
    "        #print(S_i)\n",
    "        # yi = Sigm(Si)\n",
    "        y_i = numpy.zeros(len(S_i))\n",
    "        for i in range(len(S_i)):\n",
    "            y_i[i] = 1. / (1. + numpy.exp( - S_i[i] )) # sigmoid func\n",
    "        #print(y_i)\n",
    "        # Sj = yi * wij - Tj\n",
    "        S_j = y_i.dot(weights_ij) - tresholds_j\n",
    "        #print(S_j)\n",
    "        # yj = Linear(Sj) = Sj\n",
    "        y_j = S_j\n",
    "        print('%8d\\t%24.20f\\t%24.20f\\t%24.20f' % (\n",
    "            q,\n",
    "            etalons[q + inputs],\n",
    "            y_j,\n",
    "            (etalons[q + inputs] - y_j) ** 2)\n",
    "        )\n",
    "\n",
    "    print('test:')\n",
    "    for q in range(m2 - inputs):\n",
    "        # Si = x * wki - Ti\n",
    "        x = etalons[(q + m1):(q + inputs + m1)]\n",
    "        S_i = x.dot(weights_ki) - tresholds_i\n",
    "        #print(S_i)\n",
    "        # yi = Sigm(Si)\n",
    "        y_i = numpy.zeros(len(S_i))\n",
    "        for i in range(len(S_i)):\n",
    "            y_i[i] = 1. / (1. + numpy.exp( - S_i[i] )) # sigmoid func\n",
    "        #print(y_i)\n",
    "        # Sj = yi * wij - Tj\n",
    "        S_j = y_i.dot(weights_ij) - tresholds_j\n",
    "        #print(S_j)\n",
    "        # yj = Linear(Sj) = Sj\n",
    "        y_j = S_j\n",
    "        print('%8d\\t%24.20f\\t%24.20f\\t%24.20f' % (\n",
    "            q + m1,\n",
    "            etalons[q + m1 + inputs],\n",
    "            y_j,\n",
    "            (etalons[q + m1 + inputs] - y_j) ** 2)\n",
    "        )\n",
    "\n",
    "    print('Eras: %d' % eras)\n",
    "\n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция принимает параметры:\n",
    "# m1 - number neurons for learning\n",
    "# m2 - number neurons for test\n",
    "# a - parametr for etalon function\n",
    "# b - parametr for etalon function\n",
    "# c - parametr for etalon function\n",
    "# d - parametr for etalon function\n",
    "# step - parametr for etalon function\n",
    "# inputs - number neurons\n",
    "# hiddens - number neurons\n",
    "# outputs - number neurons\n",
    "# Ee - desired squared error\n",
    "# alpha_ki - learning rate (inputs - hiddens)\n",
    "# alpha_ij - learning rate (hiddens - outputs)\n",
    "def lab3(m1, m2, a, b, c, d, step, inputs, hiddens, outputs, Ee, alpha_ki, alpha_ij):\n",
    "    # Функция возвращает массив с эталонными значениями\n",
    "    def get_etalons(n):\n",
    "        etalons = numpy.zeros(n)\n",
    "        for i in range(len(etalons)):\n",
    "            x = step * i\n",
    "            y = a * cos(b * x) + c * sin(d * x)\n",
    "            etalons[i] = y\n",
    "        return etalons\n",
    "\n",
    "    etalons = get_etalons(m1 + m2)\n",
    "    #print(etalons)\n",
    "\n",
    "    # Функция возвращает массив с весами\n",
    "    # Например, 8 нейронов в входном слое и 3 в скрытом, тогда возвратит массив 8х3\n",
    "    # Например, 3 нейрона в скрытом слое и 1 нейрон в выходном слое, тогда возвратит массив 3х1\n",
    "    def get_weights(leftNumberNeurons, rightNumberNeurons, leftRandomBorder, rightRandomBorder):\n",
    "        weights = numpy.zeros((leftNumberNeurons, rightNumberNeurons))\n",
    "        for i in range(leftNumberNeurons):\n",
    "            for j in range(rightNumberNeurons):\n",
    "                weights[i][j] = random.uniform(leftRandomBorder, rightRandomBorder)\n",
    "        return weights\n",
    "\n",
    "    weights_ki = get_weights(inputs, hiddens, -1, 1)\n",
    "    #print(weights_ki)\n",
    "\n",
    "    weights_ij = get_weights(hiddens, outputs, -1, 1)\n",
    "    #print(weights_ij)\n",
    "\n",
    "    # Функция возвращает массив с порогами\n",
    "    # Например, 8 нейронов в входном слое и 3 в скрытом, тогда возвратит массив размером 3\n",
    "    # Например, 3 нейрона в скрытом слое и 1 нейрон в выходном слое, тогда возвратит массив размером 1\n",
    "    def get_thresholds(numberNeurons, leftRandomBorder, rightRandomBorder):\n",
    "        tresholds = numpy.zeros(numberNeurons)\n",
    "        for i in range(numberNeurons):\n",
    "            tresholds[i] = random.uniform(leftRandomBorder, rightRandomBorder)\n",
    "        return tresholds\n",
    "\n",
    "    tresholds_i = get_thresholds(hiddens, -1, 1)\n",
    "    #print(tresholds_i)\n",
    "\n",
    "    tresholds_j = get_thresholds(outputs, -1, 1)\n",
    "    #print(tresholds_j)\n",
    "\n",
    "    valuesXforGraph = []\n",
    "    valuesYforGraph = []\n",
    "    eras = 0\n",
    "    while 1:\n",
    "        for q in range(m1 - inputs):\n",
    "            # Si = x * wki - Ti\n",
    "            x = etalons[q:(q+inputs)]\n",
    "            S_i = x.dot(weights_ki) - tresholds_i\n",
    "            #print(S_i)\n",
    "            # yi = Sigm(Si)\n",
    "            y_i = numpy.zeros(len(S_i))\n",
    "            for i in range(len(S_i)):\n",
    "                y_i[i] = 1. / (1. + numpy.exp( - S_i[i] )) # sigmoid func\n",
    "            #print(y_i)\n",
    "            # Sj = yi * wij - Tj\n",
    "            S_j = y_i.dot(weights_ij) - tresholds_j\n",
    "            #print(S_j)\n",
    "            # yj = Linear(Sj) = Sj\n",
    "            y_j = S_j\n",
    "            #print(y_j)\n",
    "            # jj = yj - e\n",
    "            j_j = numpy.array([ y_j[i] - etalons[q + inputs + i] for i in range(len(y_j)) ])\n",
    "            #print(j_j)\n",
    "            # ji = sum [dF(Sj) * wij]\n",
    "            dF_j = 1\n",
    "            j_i = numpy.zeros(hiddens)\n",
    "            for i in range(hiddens):\n",
    "                for j in range(outputs):\n",
    "                    j_i[i] += j_j[j] * dF_j * weights_ij[i][j]\n",
    "            #print(j_i)\n",
    "            # wij = wij - alpha * jj * dFj * yi\n",
    "            for i in range(hiddens):\n",
    "                for j in range(outputs):\n",
    "                    weights_ij[i][j] -= alpha_ij * j_j[j] * dF_j * y_j[j]\n",
    "            #print(weights_ij)\n",
    "            # Tj = Tj + alpha * jj * dFj\n",
    "            for j in range(outputs):\n",
    "                tresholds_j += alpha_ij * j_j[j] * dF_j\n",
    "            #print(tresholds_j)\n",
    "            # wki = wki - alpha * ji * dFi * yi\n",
    "            for k in range(inputs):\n",
    "                for i in range(hiddens):\n",
    "                    dFi = y_i[i] * (1 - y_i[i]) # derivative sigmoid func\n",
    "                    weights_ki[k][i] -= alpha_ki * j_i[i] * dFi * y_i[i]\n",
    "            #print(weights_ki)\n",
    "            # Ti = Ti + alpha * ji * dFi\n",
    "            for i in range(hiddens):\n",
    "                dFi = y_i[i] * (1 - y_i[i]) # derivative sigmoid func\n",
    "                tresholds_i += alpha_ki * j_i[i] * dFi\n",
    "            #print(tresholds_i)\n",
    "        E = 0\n",
    "        for j in range(outputs):\n",
    "            E += 1./2 * (y_j[j] - etalons[q + inputs + j]) ** 2\n",
    "        valuesXforGraph.append(E)\n",
    "        eras += 1\n",
    "        valuesYforGraph.append(eras)\n",
    "        print('eras: %8d\\tE: %32.20f\\r' % (eras, E), end = '')\n",
    "        if E < Ee:\n",
    "            print()\n",
    "            matplotlib.pyplot.plot(valuesYforGraph, valuesXforGraph, 'g-o')\n",
    "            matplotlib.pyplot.title('E(eras)')\n",
    "            break\n",
    "\n",
    "    print('after learning:')\n",
    "    for q in range(m1):\n",
    "        # Si = x * wki - Ti\n",
    "        x = etalons[q:(q+inputs)]\n",
    "        S_i = x.dot(weights_ki) - tresholds_i\n",
    "        #print(S_i)\n",
    "        # yi = Sigm(Si)\n",
    "        y_i = numpy.zeros(len(S_i))\n",
    "        for i in range(len(S_i)):\n",
    "            y_i[i] = 1. / (1. + numpy.exp( - S_i[i] )) # sigmoid func\n",
    "        #print(y_i)\n",
    "        # Sj = yi * wij - Tj\n",
    "        S_j = y_i.dot(weights_ij) - tresholds_j\n",
    "        #print(S_j)\n",
    "        # yj = Linear(Sj) = Sj\n",
    "        y_j = S_j\n",
    "        print('%8d\\t%24.20f\\t%24.20f\\t%24.20f' % (\n",
    "            q,\n",
    "            etalons[q + inputs],\n",
    "            y_j,\n",
    "            (etalons[q + inputs] - y_j) ** 2)\n",
    "        )\n",
    "\n",
    "    print('test:')\n",
    "    for q in range(m2 - inputs):\n",
    "        # Si = x * wki - Ti\n",
    "        x = etalons[(q + m1):(q + inputs + m1)]\n",
    "        S_i = x.dot(weights_ki) - tresholds_i\n",
    "        #print(S_i)\n",
    "        # yi = Sigm(Si)\n",
    "        y_i = numpy.zeros(len(S_i))\n",
    "        for i in range(len(S_i)):\n",
    "            y_i[i] = 1. / (1. + numpy.exp( - S_i[i] )) # sigmoid func\n",
    "        #print(y_i)\n",
    "        # Sj = yi * wij - Tj\n",
    "        S_j = y_i.dot(weights_ij) - tresholds_j\n",
    "        #print(S_j)\n",
    "        # yj = Linear(Sj) = Sj\n",
    "        y_j = S_j\n",
    "        print('%8d\\t%24.20f\\t%24.20f\\t%24.20f' % (\n",
    "            q + m1,\n",
    "            etalons[q + m1 + inputs],\n",
    "            y_j,\n",
    "            (etalons[q + m1 + inputs] - y_j) ** 2)\n",
    "        )\n",
    "\n",
    "    print('Eras: %d' % eras)\n",
    "\n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тесты при разных $\\alpha$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eras:       57\tE:           0.00000000879646263454\n",
      "after learning:\n",
      "       0\t  0.10035919904106743727\t  0.10157071920265495213\t  0.00000146778110193304\n",
      "       1\t  0.10040398613483499102\t  0.10156357524520978619\t  0.00000134464690489981\n",
      "       2\t  0.10044874812760651306\t  0.10155646151652003573\t  0.00000122702895197828\n",
      "       3\t  0.10049348500819153818\t  0.10154937786544174227\t  0.00000111490972599200\n",
      "       4\t  0.10053819676540583228\t  0.10154232414165104137\t  0.00000100827178772509\n",
      "       5\t  0.10058288338807146178\t  0.10153530019563930531\t  0.00000090709777533772\n",
      "       6\t  0.10062754486501676587\t  0.10152830587870892431\t  0.00000081137040378772\n",
      "       7\t  0.10067218118507638425\t  0.10152134104296850481\t  0.00000072107246425537\n",
      "       8\t  0.10071679233709121548\t  0.10151440554132851180\t  0.00000063618682357369\n",
      "       9\t  0.10076137830990850031\t  0.10150749922749663368\t  0.00000055669642366256\n",
      "      10\t  0.10080593909238171058\t  0.10150062195597350789\t  0.00000048258428096810\n",
      "      11\t  0.10085047467337070193\t  0.10149377358204814126\t  0.00000041383348590558\n",
      "      12\t  0.10089498504174153337\t  0.10148695396179355233\t  0.00000035042720230755\n",
      "      13\t  0.10093947018636663382\t  0.10148016295206249704\t  0.00000029234866687584\n",
      "      14\t  0.10098393009612470494\t  0.10147340041048277803\t  0.00000023958118863779\n",
      "      15\t  0.10102836475990079057\t  0.10146666619545335886\t  0.00000019210814840744\n",
      "      16\t  0.10107277416658620728\t  0.10145996016613967328\t  0.00000014991299825022\n",
      "      17\t  0.10111715830507861380\t  0.10145328218246954521\t  0.00000011297926095231\n",
      "      18\t  0.10116151716428196938\t  0.10144663210512883111\t  0.00000008129052949411\n",
      "      19\t  0.10120585073310656155\t  0.10144000979555720110\t  0.00000005483046652776\n",
      "      20\t  0.10125015900046899220\t  0.10143341511594397564\t  0.00000003358280385898\n",
      "      21\t  0.10129444195529220540\t  0.10142684792922390669\t  0.00000001753134193280\n",
      "      22\t  0.10133869958650544574\t  0.10142030809907290334\t  0.00000000665994932347\n",
      "      23\t  0.10138293188304432768\t  0.10141379548990397952\t  0.00000000095256222839\n",
      "      24\t  0.10142713883385078011\t  0.10140730996686317389\t  0.00000000039318396601\n",
      "      25\t  0.10147132042787301853\t  0.10140085139582535878\t  0.00000000496588447773\n",
      "      26\t  0.10151547665406571164\t  0.10139441964339016011\t  0.00000001465479983370\n",
      "      27\t  0.10155960750138975923\t  0.10138801457687804386\t  0.00000002944413174248\n",
      "      28\t  0.10160371295881244491\t  0.10138163606432606945\t  0.00000004931814706471\n",
      "      29\t  0.10164779301530743605\t  0.10137528397448403172\t  0.00000007426117733049\n",
      "test:\n",
      "      30\t  0.10169184765985468666\t  0.10136895817681038090\t  0.00000010425761826062\n",
      "      31\t  0.10173587688144057617\t  0.10136265854146847554\t  0.00000013929192929153\n",
      "      32\t  0.10177988066905775677\t  0.10135638493932216941\t  0.00000017934863310428\n",
      "      33\t  0.10182385901170530607\t  0.10135013724193250861\t  0.00000022441231515667\n",
      "      34\t  0.10186781189838864381\t  0.10134391532155329063\t  0.00000027446762321980\n",
      "      35\t  0.10191173931811953191\t  0.10133771905112751166\t  0.00000032949926691759\n",
      "      36\t  0.10195564125991610216\t  0.10133154830428331428\t  0.00000038949201727047\n",
      "      37\t  0.10199951771280289792\t  0.10132540295533043473\t  0.00000045443070624216\n",
      "      38\t  0.10204336866581080467\t  0.10131928287925598409\t  0.00000052430022629071\n",
      "      39\t  0.10208719410797707783\t  0.10131318795172100655\t  0.00000059908552992230\n",
      "      40\t  0.10213099402834534268\t  0.10130711804905659368\t  0.00000067877162924900\n",
      "      41\t  0.10217476841596564996\t  0.10130107304825994308\t  0.00000076334359555041\n",
      "      42\t  0.10221851725989437865\t  0.10129505282699111102\t  0.00000085278655883735\n",
      "      43\t  0.10226224054919431927\t  0.10128905726356871031\t  0.00000094708570742106\n",
      "      44\t  0.10230593827293466003\t  0.10128308623696666291\t  0.00000104622628748388\n",
      "      45\t  0.10234961042019095900\t  0.10127713962681034188\t  0.00000115019360265445\n",
      "      46\t  0.10239325698004518583\t  0.10127121731337304644\t  0.00000125897301358573\n",
      "      47\t  0.10243687794158570781\t  0.10126531917757214396\t  0.00000137254993753699\n",
      "      48\t  0.10248047329390727600\t  0.10125944510096590578\t  0.00000149090984795767\n",
      "      49\t  0.10252404302611105302\t  0.10125359496574923290\t  0.00000161403827407711\n",
      "      50\t  0.10256758712730461303\t  0.10124776865475096366\t  0.00000174192080049385\n",
      "      51\t  0.10261110558660191394\t  0.10124196605142951610\t  0.00000187454306677209\n",
      "      52\t  0.10265459839312338075\t  0.10123618703986991818\t  0.00000201189076703832\n",
      "      53\t  0.10269806553599573895\t  0.10123043150477997743\t  0.00000215394964958263\n",
      "      54\t  0.10274150700435229211\t  0.10122469933148697807\t  0.00000230070551646309\n",
      "      55\t  0.10278492278733260268\t  0.10121899040593415608\t  0.00000245214422311221\n",
      "      56\t  0.10282831287408275567\t  0.10121330461467734074\t  0.00000260825167794771\n",
      "      57\t  0.10287167725375523375\t  0.10120764184488123538\t  0.00000276901384198645\n",
      "      58\t  0.10291501591550893113\t  0.10120200198431647531\t  0.00000293441672845943\n",
      "      59\t  0.10295832884850918132\t  0.10119638492135585306\t  0.00000310444640243249\n",
      "      60\t  0.10300161604192774323\t  0.10119079054497112646\t  0.00000327908898042818\n",
      "      61\t  0.10304487748494285670\t  0.10118521874472952149\t  0.00000345833063005185\n",
      "Eras: 57\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(2)\n",
    "lab4(\n",
    "    30,     # m1 - number neurons for learning\n",
    "    40,     # m2 - number neurons for test\n",
    "    0.1,    # a - parametr for etalon function\n",
    "    0.5,    # b - parametr for etalon function\n",
    "    0.09,   # c - parametr for etalon function\n",
    "    0.5,    # d - parametr for etalon function\n",
    "    0.001,  # step - parametr for etalon function\n",
    "    8,      # inputs - number neurons\n",
    "    3,      # hiddens - number neurons\n",
    "    1,      # outputs - number neurons\n",
    "    1e-8,   # Ee - desired squared error\n",
    "    0.001,  # alpha_ki - learning rate (inputs - hiddens)\n",
    "    0.001   # alpha_ij - learning rate (hiddens - outputs)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eras:      245\tE:           0.00000000854465060502\n",
      "after learning:\n",
      "       0\t  0.10035919904106743727\t  0.10128449268241776493\t  0.00000085616832272335\n",
      "       1\t  0.10040398613483499102\t  0.10129122242407004317\t  0.00000078718823293559\n",
      "       2\t  0.10044874812760651306\t  0.10129794833760030759\t  0.00000072114099665350\n",
      "       3\t  0.10049348500819153818\t  0.10130467042144888912\t  0.00000065802177468150\n",
      "       4\t  0.10053819676540583228\t  0.10131138867405711790\t  0.00000059782572760382\n",
      "       5\t  0.10058288338807146178\t  0.10131810309386712898\t  0.00000054054801579027\n",
      "       6\t  0.10062754486501676587\t  0.10132481367932225091\t  0.00000048618379940298\n",
      "       7\t  0.10067218118507638425\t  0.10133152042886686695\t  0.00000043472823840221\n",
      "       8\t  0.10071679233709121548\t  0.10133822334094597095\t  0.00000038617649255193\n",
      "       9\t  0.10076137830990850031\t  0.10134492241400577806\t  0.00000034052372142669\n",
      "      10\t  0.10080593909238171058\t  0.10135161764649344707\t  0.00000029776508441748\n",
      "      11\t  0.10085047467337070193\t  0.10135830903685708049\t  0.00000025789574073762\n",
      "      12\t  0.10089498504174153337\t  0.10136499658354583553\t  0.00000022091084942926\n",
      "      13\t  0.10093947018636663382\t  0.10137168028500992412\t  0.00000018680556936924\n",
      "      14\t  0.10098393009612470494\t  0.10137836013970016880\t  0.00000015557505927494\n",
      "      15\t  0.10102836475990079057\t  0.10138503614606872438\t  0.00000012721447771096\n",
      "      16\t  0.10107277416658620728\t  0.10139170830256866163\t  0.00000010171898309487\n",
      "      17\t  0.10111715830507861380\t  0.10139837660765396721\t  0.00000007908373370336\n",
      "      18\t  0.10116151716428196938\t  0.10140504105977951599\t  0.00000005930388767830\n",
      "      19\t  0.10120585073310656155\t  0.10141170165740145959\t  0.00000004237460303306\n",
      "      20\t  0.10125015900046899220\t  0.10141835839897653249\t  0.00000002829103765830\n",
      "      21\t  0.10129444195529220540\t  0.10142501128296280144\t  0.00000001704834932835\n",
      "      22\t  0.10133869958650544574\t  0.10143166030781911036\t  0.00000000864169570716\n",
      "      23\t  0.10138293188304432768\t  0.10143830547200546888\t  0.00000000306623435444\n",
      "      24\t  0.10142713883385078011\t  0.10144494677398241400\t  0.00000000031712273173\n",
      "      25\t  0.10147132042787301853\t  0.10145158421221209255\t  0.00000000038951820861\n",
      "      26\t  0.10151547665406571164\t  0.10145821778515731748\t  0.00000000327857806867\n",
      "      27\t  0.10155960750138975923\t  0.10146484749128162339\t  0.00000000897945951569\n",
      "      28\t  0.10160371295881244491\t  0.10147147332905007144\t  0.00000001748731967969\n",
      "      29\t  0.10164779301530743605\t  0.10147809529692827790\t  0.00000002879731562309\n",
      "test:\n",
      "      30\t  0.10169184765985468666\t  0.10148471339338319130\t  0.00000004290460434668\n",
      "      31\t  0.10173587688144057617\t  0.10149132761688231530\t  0.00000005980434279599\n",
      "      32\t  0.10177988066905775677\t  0.10149793796589454131\t  0.00000007949168786698\n",
      "      33\t  0.10182385901170530607\t  0.10150454443888937139\t  0.00000010196179641262\n",
      "      34\t  0.10186781189838864381\t  0.10151114703433758435\t  0.00000012720982524856\n",
      "      35\t  0.10191173931811953191\t  0.10151774575071101370\t  0.00000015523093115929\n",
      "      36\t  0.10195564125991610216\t  0.10152434058648204807\t  0.00000018602027090467\n",
      "      37\t  0.10199951771280289792\t  0.10153093154012457489\t  0.00000021957300122532\n",
      "      38\t  0.10204336866581080467\t  0.10153751861011275914\t  0.00000025588427884972\n",
      "      39\t  0.10208719410797707783\t  0.10154410179492276423\t  0.00000029494926049868\n",
      "      40\t  0.10213099402834534268\t  0.10155068109303072577\t  0.00000033676310289347\n",
      "      41\t  0.10217476841596564996\t  0.10155725650291444473\t  0.00000038132096276016\n",
      "      42\t  0.10221851725989437865\t  0.10156382802305244373\t  0.00000042861799683668\n",
      "      43\t  0.10226224054919431927\t  0.10157039565192424457\t  0.00000047864936187864\n",
      "      44\t  0.10230593827293466003\t  0.10157695938801034052\t  0.00000053141021466550\n",
      "      45\t  0.10234961042019095900\t  0.10158351922979227955\t  0.00000058689571200647\n",
      "      46\t  0.10239325698004518583\t  0.10159007517575244228\t  0.00000064510101074695\n",
      "      47\t  0.10243687794158570781\t  0.10159662722437443061\t  0.00000070602126777407\n",
      "      48\t  0.10248047329390727600\t  0.10160317537414279010\t  0.00000076965164002309\n",
      "      49\t  0.10252404302611105302\t  0.10160971962354264919\t  0.00000083598728448426\n",
      "      50\t  0.10256758712730461303\t  0.10161625997106080166\t  0.00000090502335820694\n",
      "      51\t  0.10261110558660191394\t  0.10162279641518448536\t  0.00000097675501830780\n",
      "      52\t  0.10265459839312338075\t  0.10162932895440215941\t  0.00000105117742197573\n",
      "      53\t  0.10269806553599573895\t  0.10163585758720319885\t  0.00000112828572647806\n",
      "      54\t  0.10274150700435229211\t  0.10164238231207786689\t  0.00000120807508916735\n",
      "      55\t  0.10278492278733260268\t  0.10164890312751789780\t  0.00000129054066748552\n",
      "      56\t  0.10282831287408275567\t  0.10165542003201530341\t  0.00000137567761897307\n",
      "      57\t  0.10287167725375523375\t  0.10166193302406348331\t  0.00000146348110127249\n",
      "      58\t  0.10291501591550893113\t  0.10166844210215700284\t  0.00000155394627213477\n",
      "      59\t  0.10295832884850918132\t  0.10167494726479095468\t  0.00000164706828942710\n",
      "      60\t  0.10300161604192774323\t  0.10168144851046165278\t  0.00000174284231113727\n",
      "      61\t  0.10304487748494285670\t  0.10168794583766646578\t  0.00000184126349538022\n",
      "Eras: 245\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(2)\n",
    "lab3(\n",
    "    30,     # m1 - number neurons for learning\n",
    "    40,     # m2 - number neurons for test\n",
    "    0.1,    # a - parametr for etalon function\n",
    "    0.5,    # b - parametr for etalon function\n",
    "    0.09,   # c - parametr for etalon function\n",
    "    0.5,    # d - parametr for etalon function\n",
    "    0.001,  # step - parametr for etalon function\n",
    "    8,      # inputs - number neurons\n",
    "    3,      # hiddens - number neurons\n",
    "    1,      # outputs - number neurons\n",
    "    1e-8,   # Ee - desired squared error\n",
    "    0.001,  # alpha_ki - learning rate (inputs - hiddens)\n",
    "    0.001   # alpha_ij - learning rate (hiddens - outputs)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
