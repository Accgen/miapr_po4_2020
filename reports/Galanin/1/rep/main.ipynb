{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №1\n",
    "\n",
    "**Тема**: \"Линейная искусственная нейронная сеть. Правило Видроу-Хоффа\".\n",
    "\n",
    "**Цель**: \"Изучить обучение и функционирование линейной ИНС при решении задач прогнозирования\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лекция:**\n",
    "\n",
    "Алгоритм\n",
    "\n",
    "1. Случайная инициализация весов и порогов в достаточно узком диапазоне значений $\\omega, T \\in [0; 1]$\n",
    "\n",
    "2. Значения шага обучения $\\alpha = const \\in (0; 1)$ и значение желаемой суммарной квадратичной ошибки сети $E_e$ до уровня, которой мы хотим обучить сеть.\n",
    "\n",
    "3. Последовательно подаются входные образы из обучающей выборки на нейронную сеть. $k = \\overline{1,j}$ - кол-во образов обучающей выборки. И для каждого образа производятся следующие действия:\n",
    "\n",
    "    1. Вычисляются входные значения сети:\n",
    "        \n",
    "        $y_i = \\sum\\limits_{i = 1}^n \\omega_{ij} x_{i} - T{ij}$\n",
    "        \n",
    "        $j = \\overline{1, m}$\n",
    "        \n",
    "    2. В соотвествии с дельта правилом производится модификация весов и порогов:\n",
    "    \n",
    "        $\\omega_{ij}(t+1) = \\omega_{ij}(t) - \\alpha x_i(y_i - e_i)$\n",
    "        \n",
    "        $T_j(t+1) = T_j(t) + \\alpha (y_j - e_j)$\n",
    "        \n",
    "        $i = \\overline{1, n}$, $j = \\overline{1, m}$\n",
    "        \n",
    "4. Последовательно подаются входные образы из обучающей выборки на нейронную сеть $k = \\overline{1, n}$ и вычисляются значения сумарной квадратичной ошибки сети\n",
    "\n",
    "    $E_s = {1 \\over 2} \\sum\\limits_{k=1}^L \\sum\\limits_{j=1}^m (y_j^k - e_j^k)^2$\n",
    "    \n",
    "5. Происходит сравнение суммарной квадратичной ошибки сети и желаемой. Если $E_s > E_e$, то алгоритм продолжается начиная с пункта 3, в противном случае обучение заканчивается.\n",
    "\n",
    "**Примичание** Другой критерий остановки алгоритма\n",
    "\n",
    "Алгоритм обучения заканчивается, когда перестаёт уменьшаться значение суммарной квадратичной ошибки сети или её уменьшение происходит не значительно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ход работы:**\n",
    "\n",
    "**Вариант 5**\n",
    "\n",
    "| Вариант | a | b | d  | Кол-во входов ИНС |\n",
    "|:-------:|:-:|:-:|:--:|:-----------------:|\n",
    "| 5       | 1 | 9 | 0.5| 4                 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a = 1.000000000000       - parametr for function y\n",
      "     b = 9.000000000000       - parametr for function y\n",
      "     d = 0.500000000000       - parametr for function y\n",
      "     L = 4                    - numbers of inputs NN\n",
      "    Em = 0.000000000010       - minimal squared error\n",
      "     T = 0.500000000000       - Threshold\n",
      "     m = 30                   - number of training iterations\n",
      "    m2 = 15                   - number of forecasting iterations\n",
      "w[  0] =       0.006744760783 - weight\n",
      "w[  1] =      -0.006256402693 - weight\n",
      "w[  2] =       0.002241137767 - weight\n",
      "w[  3] =      -0.000799699573 - weight\n",
      "e[  0] =       0.500000000000 - etalon value\n",
      "e[  1] =       1.283326909627 - etalon value\n",
      "e[  2] =       1.473847630878 - etalon value\n",
      "e[  3] =       0.927379880234 - etalon value\n",
      "e[  4] =       0.057479556705 - etalon value\n",
      "e[  5] =      -0.477530117665 - etalon value\n",
      "e[  6] =      -0.272764487556 - etalon value\n",
      "e[  7] =       0.516813900484 - etalon value\n",
      "e[  8] =       1.293667863849 - etalon value\n",
      "e[  9] =       1.469889810845 - etalon value\n",
      "e[ 10] =       0.912118485242 - etalon value\n",
      "e[ 11] =       0.042464106225 - etalon value\n",
      "e[ 12] =      -0.480936230066 - etalon value\n",
      "e[ 13] =      -0.261983583919 - etalon value\n",
      "e[ 14] =       0.533623047221 - etalon value\n",
      "e[ 15] =       1.303784426552 - etalon value\n",
      "e[ 16] =       1.465657776549 - etalon value\n",
      "e[ 17] =       0.896740573131 - etalon value\n",
      "e[ 18] =       0.027578013602 - etalon value\n",
      "e[ 19] =      -0.484065005082 - etalon value\n",
      "e[ 20] =      -0.250987246772 - etalon value\n",
      "e[ 21] =       0.550422687807 - etalon value\n",
      "e[ 22] =       1.313673737507 - etalon value\n",
      "e[ 23] =       1.461152724502 - etalon value\n",
      "e[ 24] =       0.881250491655 - etalon value\n",
      "e[ 25] =       0.012825487539 - etalon value\n",
      "e[ 26] =      -0.486915558121 - etalon value\n",
      "e[ 27] =      -0.239778585078 - etalon value\n",
      "e[ 28] =       0.567208072525 - etalon value\n",
      "e[ 29] =       1.323333000738 - etalon value\n",
      "e[ 30] =       1.456375928405 - etalon value\n",
      "e[ 31] =       0.865652620283 - etalon value\n",
      "e[ 32] =      -0.001789301021 - etalon value\n",
      "e[ 33] =      -0.489487083255 - etalon value\n",
      "e[ 34] =      -0.228360767832 - etalon value\n",
      "e[ 35] =       0.583974455692 - etalon value\n",
      "e[ 36] =       1.332759485308 - etalon value\n",
      "e[ 37] =       1.451328738787 - etalon value\n",
      "e[ 38] =       0.849951368957 - etalon value\n",
      "e[ 39] =      -0.016262220080 - etalon value\n",
      "e[ 40] =      -0.491778853443 - etalon value\n",
      "e[ 41] =      -0.216737023161 - etalon value\n",
      "e[ 42] =       0.600717096993 - etalon value\n",
      "e[ 43] =       1.341950526092 - etalon value\n",
      "e[ 44] =       1.446012582627 - etalon value\n",
      "|                 Eras |                    E |\n",
      "| -------------------- | -------------------- |\n",
      "|                   26 |      36.917225954627 |\n",
      "|                   52 |       0.044252973774 |\n",
      "|                   78 |       0.000273912511 |\n",
      "|                  104 |       0.000000055801 |\n",
      "|                  130 |       0.000000000469 |\n",
      "|                  156 |       0.000000000000 |\n",
      "Result learning\n",
      "|                  y[] |   Эталонное значение |  Полученное значение |           Отклонение |\n",
      "| -------------------- | -------------------- | -------------------- | -------------------- |\n",
      "|                    0 |       0.057479556705 |       0.057479548354 |       0.000000008352 |\n",
      "|                    1 |      -0.477530117665 |      -0.477530122435 |       0.000000004770 |\n",
      "|                    2 |      -0.272764487556 |      -0.272764487914 |       0.000000000358 |\n",
      "|                    3 |       0.516813900484 |       0.516813902032 |      -0.000000001547 |\n",
      "|                    4 |       1.293667863849 |       1.293667863352 |       0.000000000497 |\n",
      "|                    5 |       1.469889810845 |       1.469889805901 |       0.000000004944 |\n",
      "|                    6 |       0.912118485242 |       0.912118476814 |       0.000000008428 |\n",
      "|                    7 |       0.042464106225 |       0.042464097913 |       0.000000008312 |\n",
      "|                    8 |      -0.480936230066 |      -0.480936234751 |       0.000000004684 |\n",
      "|                    9 |      -0.261983583919 |      -0.261983584209 |       0.000000000290 |\n",
      "|                   10 |       0.533623047221 |       0.533623048766 |      -0.000000001545 |\n",
      "|                   11 |       1.303784426552 |       1.303784425984 |       0.000000000567 |\n",
      "|                   12 |       1.465657776549 |       1.465657771520 |       0.000000005029 |\n",
      "|                   13 |       0.896740573131 |       0.896740564667 |       0.000000008463 |\n",
      "|                   14 |       0.027578013602 |       0.027578005330 |       0.000000008271 |\n",
      "|                   15 |      -0.484065005082 |      -0.484065009680 |       0.000000004598 |\n",
      "|                   16 |      -0.250987246772 |      -0.250987246995 |       0.000000000224 |\n",
      "|                   17 |       0.550422687807 |       0.550422689348 |      -0.000000001541 |\n",
      "|                   18 |       1.313673737507 |       1.313673736869 |       0.000000000638 |\n",
      "|                   19 |       1.461152724502 |       1.461152719388 |       0.000000005114 |\n",
      "|                   20 |       0.881250491655 |       0.881250483157 |       0.000000008497 |\n",
      "|                   21 |       0.012825487539 |       0.012825479310 |       0.000000008229 |\n",
      "|                   22 |      -0.486915558121 |      -0.486915562632 |       0.000000004512 |\n",
      "|                   23 |      -0.239778585078 |      -0.239778585236 |       0.000000000158 |\n",
      "|                   24 |       0.567208072525 |       0.567208074062 |      -0.000000001536 |\n",
      "|                   25 |       1.323333000738 |       1.323333000028 |       0.000000000710 |\n",
      "|                   26 |       1.456375928405 |       1.456375923207 |       0.000000005198 |\n",
      "|                   27 |       0.865652620283 |       0.865652611752 |       0.000000008530 |\n",
      "|                   28 |      -0.001789301021 |      -0.001789309206 |       0.000000008186 |\n",
      "|                   29 |      -0.489487083255 |      -0.489487087679 |       0.000000004425 |\n",
      "Results forecasting\n",
      "|                  y[] |   Эталонное значение |  Полученное значение |           Отклонение |\n",
      "| -------------------- | -------------------- | -------------------- | -------------------- |\n",
      "|                   30 |       1.456375928405 |       1.456375923207 |       0.000000005198 |\n",
      "|                   31 |       0.865652620283 |       0.865652611752 |       0.000000008530 |\n",
      "|                   32 |      -0.001789301021 |      -0.001789309206 |       0.000000008186 |\n",
      "|                   33 |      -0.489487083255 |      -0.489487087679 |       0.000000004425 |\n",
      "|                   34 |      -0.228360767832 |      -0.228360767926 |       0.000000000094 |\n",
      "|                   35 |       0.583974455692 |       0.583974457221 |      -0.000000001530 |\n",
      "|                   36 |       1.332759485308 |       1.332759484525 |       0.000000000783 |\n",
      "|                   37 |       1.451328738787 |       1.451328733505 |       0.000000005282 |\n",
      "|                   38 |       0.849951368957 |       0.849951360395 |       0.000000008562 |\n",
      "|                   39 |      -0.016262220080 |      -0.016262228221 |       0.000000008141 |\n",
      "|                   40 |      -0.491778853443 |      -0.491778857781 |       0.000000004338 |\n",
      "|                   41 |      -0.216737023161 |      -0.216737023191 |       0.000000000031 |\n",
      "|                   42 |       0.600717096993 |       0.600717098514 |      -0.000000001521 |\n",
      "|                   43 |       1.341950526092 |       1.341950525236 |       0.000000000857 |\n",
      "|                   44 |       1.446012582627 |       1.446012577262 |       0.000000005365 |\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class lab():\n",
    "\tdef __init__(self, a, b, d, L, Em, T, m, m2):\n",
    "\t\tself.a = a\n",
    "\t\tprint(\"%6s = %-20.12f - parametr for function y\" % (\"a\", self.a))\n",
    "\n",
    "\t\tself.b = b\n",
    "\t\tprint(\"%6s = %-20.12f - parametr for function y\" % (\"b\", self.b))\n",
    "\n",
    "\t\tself.d = d\n",
    "\t\tprint(\"%6s = %-20.12f - parametr for function y\" % (\"d\", self.d))\n",
    "\n",
    "\t\tself.L = L\n",
    "\t\tprint(\"%6s = %-20d - numbers of inputs NN\" % (\"L\", self.L))\n",
    "\n",
    "\t\tself.Em = Em\n",
    "\t\tprint(\"%6s = %-20.12f - minimal squared error\" % (\"Em\", self.Em))\n",
    "\n",
    "\t\tself.T = T\n",
    "\t\tprint(\"%6s = %-20.12f - Threshold\" % (\"T\", self.T))\n",
    "\n",
    "\t\tself.m = m\n",
    "\t\tprint(\"%6s = %-20d - number of training iterations\" % (\"m\", self.m))\n",
    "\n",
    "\t\tself.m2 = m2\n",
    "\t\tprint(\"%6s = %-20d - number of forecasting iterations\" % (\"m2\", self.m2))\n",
    "\n",
    "\tdef generate_w(self, left_point, right_point):\n",
    "\t\tself.w = []\n",
    "\t\tfor i in range(self.L):\n",
    "\t\t\tself.w.append(random.random() * right_point - left_point)\n",
    "\t\t\t\n",
    "\tdef print_w(self):\n",
    "\t\tfor i in range(self.L):\n",
    "\t\t\tprint(\"w[%3d] = %20.12f - weight\" % (i, self.w[i]))\n",
    "\n",
    "\tdef generate_e(self, step):\n",
    "\t\tself.e = []\n",
    "\t\tfor i in range(self.m + self.m2):\n",
    "\t\t\tx = step * i\n",
    "\t\t\tresult = self.a * math.sin( self.b * x ) + self.d\n",
    "\t\t\tself.e.append(result)\n",
    "\n",
    "\tdef print_e(self):\n",
    "\t\tfor i in range(self.m + self.m2):\n",
    "\t\t\tprint(\"e[%3d] = %20.12f - etalon value\" % (i, self.e[i]))\n",
    "\n",
    "\tdef WidrowHoffAlgorithm_constAlpha(self, alpha):\n",
    "\t\tprint(\"| %20s | %20s |\" % (\"Eras\", \"E\"))\n",
    "\t\tprint(\"| %16s | %16s |\" % (\"--------------------\", \"--------------------\"))\n",
    "\n",
    "\t\teras = 0\n",
    "\t\tvalueXforGraph = []\n",
    "\t\tvalueYforGraph = []\n",
    "\t\twhile 1:\n",
    "\t\t\tE = 0\n",
    "\t\t\tfor i in range(self.m - self.L):\n",
    "\t\t\t\ty1 = 0\n",
    "\t\t\t\tfor j in range(self.L):\n",
    "\t\t\t\t\ty1 += self.w[j] * self.e[i + j]\n",
    "\t\t\t\ty1 -= self.T\n",
    "\t\t\t\tfor j in range(self.L):\n",
    "\t\t\t\t\tself.w[j] -= alpha * (y1 - self.e[i + self.L]) * self.e[i + j]\n",
    "\t\t\t\tself.T += alpha * (y1 - self.e[i + self.L])\n",
    "\t\t\t\tE += 0.5 * math.pow( (y1 - self.e[i + self.L]), 2 )\n",
    "\t\t\t\teras += 1\n",
    "\n",
    "\t\t\tprint(\"| %20d | %20.12f |\" % (eras, E))\n",
    "\t\t\tvalueXforGraph.append(eras)\n",
    "\t\t\tvalueYforGraph.append(E)\n",
    "\n",
    "\t\t\tif E < self.Em:\n",
    "\t\t\t\tbreak\n",
    "\t\tplt.plot(valueXforGraph, valueYforGraph, 'Db', label=\"Contantly alpha\")\n",
    "\n",
    "\tdef printResult(self):\n",
    "\t\tdef print_headTable():\n",
    "\t\t\tprint(\"| %20s | %20s | %20s | %20s |\" % (\n",
    "\t\t\t\t\"y[]\",\n",
    "\t\t\t\t\"Эталонное значение\",\n",
    "\t\t\t\t\"Полученное значение\",\n",
    "\t\t\t\t\"Отклонение\"\n",
    "\t\t\t))\n",
    "\t\t\tprint(\"| %16s | %16s | %16s | %16s |\" % (\n",
    "\t\t\t\t\"--------------------\",\n",
    "\t\t\t\t\"--------------------\",\n",
    "\t\t\t\t\"--------------------\",\n",
    "\t\t\t\t\"--------------------\"\n",
    "\t\t\t))\n",
    "\n",
    "\t\ttrainingSample = []\n",
    "\t\tprint(\"Result learning\")\n",
    "\t\tprint_headTable()\n",
    "\t\tfor i in range(self.m):\n",
    "\t\t\ttrainingSample.append(0)\n",
    "\t\t\tfor j in range(self.L):\n",
    "\t\t\t\ttrainingSample[i] += self.w[j] * self.e[j + i]\n",
    "\t\t\ttrainingSample[i] -= self.T\n",
    "\t\t\tprint(\"| %20d | %20.12f | %20.12f | %20.12f |\" % (\n",
    "\t\t\t\ti,\n",
    "\t\t\t\tself.e[i + self.L],\n",
    "\t\t\t\ttrainingSample[i],\n",
    "\t\t\t\tself.e[i + self.L] - trainingSample[i]\n",
    "\t\t\t))\n",
    "\t\t\n",
    "\t\tprint(\"Results forecasting\")\n",
    "\t\tprint_headTable()\n",
    "\t\tfor i in range(self.m2):\n",
    "\t\t\ttrainingSample.append(0)\n",
    "\t\t\tfor j in range(self.L):\n",
    "\t\t\t\ttrainingSample[i + self.m] += self.w[j] * self.e[self.m - self.L + j + i]\n",
    "\t\t\ttrainingSample[i + self.m] -= self.T\n",
    "\t\t\tprint(\"| %20d | %20.12f | %20.12f | %20.12f |\" % (\n",
    "\t\t\t\ti + self.m,\n",
    "\t\t\t\tself.e[i + self.m],\n",
    "\t\t\t\ttrainingSample[i + self.m],\n",
    "\t\t\t\tself.e[i + self.m] - trainingSample[i + self.m]\n",
    "\t\t\t))\n",
    "\n",
    "\"\"\"Main\"\"\"\n",
    "\t\n",
    "x = lab(\n",
    "\t1,\t\t# a argument for function y\n",
    "\t9,\t\t# b argument for function y\n",
    "\t0.5,\t# d argument for function y\n",
    "\t4,\t\t# L number of inputs NN\n",
    "\t1e-11,\t# Em argument for algorithm\n",
    "\t0.5,\t# T argument for algorithm\n",
    "\t30,\t\t# m number of operations for training results\n",
    "\t15,\t\t# m2 numper of operation for forecasting results\n",
    ")\n",
    "\n",
    "x.generate_w(0.01, 0.02) # arguments (left_point, right_point)\n",
    "x.print_w()\n",
    "\n",
    "x.generate_e(0.1) # argument (step) for y\n",
    "x.print_e()\n",
    "\n",
    "x.WidrowHoffAlgorithm_constAlpha(0.5) # argument (alpha)\n",
    "x.printResult()\n",
    "\n",
    "plt.title(\"Error change graph\") # Python write title in graph\n",
    "plt.legend() # Python write legend in graph\n",
    "plt.show() # Python open new windows and show graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**: \"Изучили обучение и функционирование линейной ИНС при решении задач прогнозирования\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
